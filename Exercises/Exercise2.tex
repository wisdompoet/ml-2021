
\documentclass{article}

\usepackage{color}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{textpos}
\usepackage{amsmath}
\usepackage{hyperref}

%\usetheme{Berlin}
%\usecolortheme{seahorse}
%\usefonttheme{professionalfonts}

\begin{document}

  \section*{Programming Exercise 2}

  {\bf Due on 17 November}\\

  Pick a classification dataset from the LIBSVM repository:\\

  \url{http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/}\\

  \noindent
  {\bf Tasks:}

  \begin{enumerate}
  \item \textbf{Decision Trees}: Partition the dataset into a training and a testing set. Run a decision tree learning algorithm using the training set. Test the decision tree on the testing dataset and report the total classification error (i.e.~$0/1$ error). Repeat the experiment with a different partition. Plot the resulting trees. Are they very similar, or very different? Explain why.\\ \emph{Advice: it can be convenient to set a maximum depth for the tree.}
  \item \textbf{Support Vector Machines}: Run SVM to train a classifier, using radial basis as kernel function. Apply cross-validation to evaluate different combinations of values of the model hyper-parameters (box constraint $C$ and kernel parameter $\gamma$). How sensitive is the cross-validation error to changes in $C$ and $\gamma$? Choose the combination of $C$ and $\gamma$ that minimizes the cross-validation error, train the SVM on the entire dataset and report the total classification error.\\
\emph{Advice: consider a binary class problem. Use a logaritmic ranges for $\gamma$ and $C$.}
  \item \textbf{Neural Networks}: Train a Multi-Layer perceptron using the cross-entropy loss with $\ell$-2 regularization (weight decay penalty). In other words, the activation function equals the logistic function. Plot curves of the training and validation error as a function of the penalty strength $\alpha$.
 How do the curves behave? Explain why.\\
\emph{Advice: use a logaritmic range for hyper-parameter $\alpha$. Experiment with different sizes of the training/validation sets and different model parameters (network layers).}
  \end{enumerate}

  Attach the source code for each section. You are free to use the programming language/library of your choice.
	We recommend scikit-learn:\\

 \url{https://scikit-learn.org/stable/index.html}

\end{document}
