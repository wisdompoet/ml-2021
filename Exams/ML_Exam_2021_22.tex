\documentclass[11pt]{article}
\input{header}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{decorations.text}
\usetikzlibrary{bayesnet}

\usetikzlibrary{arrows,automata,positioning}
\usetikzlibrary{shapes.multipart}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{intersections, pgfplots.fillbetween}

\setlength{\textheight}{11.00in}
\setlength{\topmargin}{-0.2in}

\title{
\vspace{-1.2cm}
Machine Learning 2021-22\\ Final Exam}
\author{14 December 2021}
\date{Name: \dotfill}% NIA: \dotfill}

\newcounter{marks}
\setcounter{marks}{0}

\def\ci{\perp\!\!\!\perp}

\begin{document}

\maketitle

\newcounter{PreguntaCounter}

\begin{list}{{\bf Question \arabic{PreguntaCounter}:}}
	{\usecounter{PreguntaCounter}
	}

\item
\fbox{2 points}
\addtocounter{marks}{2}
Show that the two univariate functions $e^x$ and $x\log x$ are convex for $x>0$.\\
Hints: $\frac \partial {\partial x} e^x = e^x$, $\frac \partial {\partial x} \log x = \frac 1 x$, $\frac \partial {\partial x} x^p = p \cdot x^{p-1}$, and $\frac \partial {\partial x} \left( f(x) \cdot g(x) \right) = \frac {\partial f(x)} {\partial x} \cdot g(x) + f(x) \cdot\frac {\partial g(x)} {\partial x}$.

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{7cm}
}}

\item
\fbox{2 points}
\addtocounter{marks}{2}
Solve the following constrained optimization problem:
  \begin{align*}
	\max_{x,y} \; & xy\\
	\mathrm{s.t.} \; & x + 2y = 1
  \end{align*}
  Indicate the optimal value of $x$ and $y$ as well as the optimal value of the objective.

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{7cm}
}}

\pagebreak



\item
\fbox{1 point}
\addtocounter{marks}{1}
Which is the objective of $k$-means clustering? How does the $k$-means algorithm approximate a solution to this objective?

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{6.5cm}
}}

\item
\fbox{1 point}
\addtocounter{marks}{1}
Briefly explain the backpropagation algorithm, and describe how the algorithm can be efficiently implemented.

\framebox[16cm][l]{
\parbox{15.9cm}{
\vspace*{6.5cm}
}}

\item
\fbox{1 point}
\addtocounter{marks}{1}
Explain how a convolutional layer works in deep learning. How are convolutional layers implemented in practice? What changes do we have to make to standard backpropagation?

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{6.5cm}
}}



\pagebreak

Name: \dotfill

\item
\fbox{2 point}
\addtocounter{marks}{1}


\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{9cm}
}}

\item
\fbox{2 point}
\addtocounter{marks}{1}


\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{9cm}
}}



\pagebreak

Name: \dotfill

\item
\fbox{1 point}
\addtocounter{marks}{1}
A Bayesian network models the relation between the variables oil ($oil$), inflation ($inf$), economy health~($eh$), British petroleum stock price ($bp$), and retailer stock price ($rt$).
\begin{figure}[!th]
\begin{center}
\begin{tikzpicture}
  % Define nodes
  \node[latent]             (oil) {$oil$};
  \node[latent, right=of oil]             (eh) {$eh$};
  \node[latent, below=of eh]              (rt) {$rt$};
  \node[latent, left=of rt]            (inf) {$inf$};
  \node[latent, below=of inf, xshift=-1cm]   (bp) {$bp$};
  % Connect the nodes
  \edge {eh} {oil} ; %
  \edge {oil} {inf} ; %
  \edge {eh} {rt} ; %
  \edge {inf} {rt} ; %
  \edge {eh} {inf} ; %
  \edge {oil} {bp} ; %
  \end{tikzpicture}
 \caption{A simple Bayesian network}\label{fig:oil}
\end{center}
\end{figure}
\vspace{-1cm}
   \begin{enumerate}
    \item Write down the corresponding factorization of the joint probability distribution.
    \item Use the D-Separation algorithm to determine whether the following conditional independences.
\begin{enumerate}
\item Is $eh$ independent of $bp$ if no evidence is provided? Why?
\item Is $eh$ independent of $bp$ if we observe that the $oil$ is $high$? Why?
\item Is $rt$ independent of $bp$ if we observe that $eh$ is $low$? Why?
\end{enumerate}
\end{enumerate}
\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{4.5cm}
}}

\item
\fbox{1 point}
\addtocounter{marks}{1}
We aquire some data $\mathcal{D}$ consisting on $N$ independent and identically distributed samples $x_i, i = 1,\hdots,N$ at different times.
We assume a Gaussian generative model for $\mathcal{D}$ with constant variance $\sigma^2$ and mean determined by the output of a time-dependent model $F_{\boldsymbol{\theta}}(t)$ with parameters $\boldsymbol{\theta}$.
\vspace{-.3cm}
\begin{enumerate}
\item Write down the formula for the corresponding likelihood function of $\boldsymbol{\theta}$ for fixed $\mathcal{D}$.
\item Explain how the Bayes theorem can be used to update the parameters $\boldsymbol{\theta}$ in light of $\mathcal{D}$.\\
\end{enumerate}
\vspace{-.6cm}
Hint: A Gaussian distributed variable $y$ with mean $\mu$ and variance $\sigma^2$ has density $f(y)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{y-\mu}{\sigma}\right)^2}$.

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{5cm}
}}

\item
\fbox{2 points}
\addtocounter{marks}{2}
Describe qualitatively in what consists the mechanism called \emph{attention} in deep learning and how attention is integrated in the Transformer network.
You can help yourself with a diagram.

\framebox[16cm][l]{ 
\parbox{15.9cm}{
\vspace*{7.5cm}
}}


\end{list}


\end{document}
